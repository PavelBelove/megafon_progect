{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1065b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import luigi\n",
    "import warnings\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from sklearn import set_config\n",
    "\n",
    "from functions import reduce_mem_usage\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imblearn #, Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70017196",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictProbability(luigi.Task):\n",
    "    \n",
    "    data_test = luigi.Parameter()\n",
    "    data_features = luigi.Parameter()\n",
    "  \n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        # load data\n",
    "        test = pd.read_csv(self.test_csv)\n",
    "        data_features = dd.read_csv(FEATURES_PATH, sep ='\\t')\n",
    "        \n",
    "        # merge data\n",
    "        ids = np.unique(test['id'])\n",
    "        data_features = data_features[data_features['id'].isin(ids)]\n",
    "        data_features = data_features.compute()\n",
    "        # удалим признаки с единственным значением\n",
    "        df_nunique = data_features.apply(lambda x: x.nunique(dropna=False))\n",
    "        const = df_nunique[df_nunique ==1].index.tolist()\n",
    "        data_features = data_features.drop(columns = const)\n",
    "        # функция сжатия данных\n",
    "        data_features = reduce_mem_usage(data_features)\n",
    "        \n",
    "        # сортируем и мерджим\n",
    "        data_test = data_test.sort_values(by=\"buy_time\")\n",
    "        forward = data_features.sort_values(by=\"buy_time\")\n",
    "    \n",
    "        valid = pd.merge_asof(data_features, data_test,  on='buy_time', by='id', direction ='forward')        \n",
    "        \n",
    "        features = [f for f in data_features.columns if f not in ['buy_time','id']]\n",
    "\n",
    "        # load models\n",
    "              \n",
    "        with open('fs_pipe.pkl', 'rb') as model_file:\n",
    "            fs_pipe = pickle.load(model_file)\n",
    "        \n",
    "        with open('model.pkl', 'rb') as f:\n",
    "            model = pickle.load(model_file)        \n",
    "\n",
    "        # transform data\n",
    "        X_valid = fs_pipe.transform(X_valid)\n",
    "        \n",
    "        # predict\n",
    "        answers_test = test\n",
    "\n",
    "        answers_test['target'] = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # save result        \n",
    "        \n",
    "        answers_test.to_csv('answers_test.csv', float_format='%20f', index=False, encoding='utf8',sep=',')\n",
    "        \n",
    "  \n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('answers_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    luigi.build([PredictProbability('data_test.csv')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
